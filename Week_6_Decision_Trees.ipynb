{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rawbBiJk2m3C"
   },
   "source": [
    "# Week 6 Decision Trees\n",
    "\n",
    "## Learning objectives\n",
    "By the end of this module, you will be able to:\n",
    "1. Explain each component in a decision tree.\n",
    "3. Make a prediction for a data point given a decision tree.\n",
    "2. Explain the advantages of decision trees.\n",
    "3. Create a decision tree for a dataset by using `sklearn' in Python.\n",
    "4. Adjust decision tree parameters for a specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc2hvlR2VccR"
   },
   "source": [
    "### Introducing Decision Trees\n",
    "\n",
    "A Decision Tree is a popular supervised learning method that aims to make predictions through a series of decisions or questions, creating a branching structure of decisions. Building a decision tree entails developing a set of questions for the input data to answer.\n",
    "\n",
    "Decision Trees are commonly used for **classification** and **regression** tasks. A classification task predicts the value of a discrete, categorical variable, for example, determining if a patient has a particular disease given the results of a complete blood count. In contrast, a regression task predicts the value of a continuous variable, such as predicting the concentration of a protein given the expression levels of a set of genes.\n",
    "\n",
    "\n",
    "Let's start with some definitions:\n",
    "- <span style=\"background-color: #AFEEEE\">**Decision Node**</span>: Each decision node looks at a feature and asks a true/false question regarding the value of the feature (commonly whether or not the feature is below a certain value). Depending on the answer to the question, we will choose a branch to follow. For example, we could ask if `age <= 0.25`. If this condition is met, we will go to the left branch, otherwise, we will go to the right branch. These are also called internal nodes. One special case of an internal node is the **root node**, which is the topmost node of the tree where *all* points start.\n",
    "- <span style=\"background-color: #AFEEEE\">**Leaf Node**</span>: Leaf nodes are the nodes of the tree where all samples reach after a series of decision nodes. Leaf nodes do not \"ask a question\" but rather assign a prediction to the sample. In classification tasks, this is the class of the sample (eg. true or false, type of gene, etc.). For regression tasks, this is a real value.\n",
    "- <span style=\"background-color: #AFEEEE\">**Branch**</span>: Branches connect all nodes together. Each branch corresponds to the answer to the question of the node above (`True` or `False`).\n",
    "- <span style=\"background-color: #AFEEEE\">**Node Depth**</span>: The depth of a node is equal to the number of decisions it takes to reach that node + 1. For example, the depth of the root node is 1 as no decision is made before it (0 + 1).\n",
    "- <span style=\"background-color: #AFEEEE\">**Tree Depth**</span>: The depth of the tree is equal to the depth of the deepest internal node.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ohMQqOyo7x_"
   },
   "source": [
    "Here is a diagram of the structure of a decision tree with each component labelled:\n",
    "\n",
    "![elements of a decision tree](images/element_of_decision_tree.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CoTEBGHca8j"
   },
   "source": [
    "#### **Real-life Example**\n",
    "Recall that in HMB201, we used a dataset on heart failure patients, containing data on 299 patients' characteristics such as age, sex, and whether they smoke (i.e., features), and also containing whether or not the patient died from heart failure.\n",
    "\n",
    "Using the dataset, we trained a decision tree that aims to predict death in heart failure patients. The tree is used to make a binary decision given a patient's features. The tree is visualized below.\n",
    "\n",
    "![name](images/heart_failure_decision_tree.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OwnSUyd40p-"
   },
   "source": [
    "Each node in the diagram has 3-4 pieces of information:\n",
    "1. Decision Rule (not present in leaf nodes)\n",
    "2. Number of samples reaching the node\n",
    "3. Number of samples in each class (No Death, Death)\n",
    "4. Majority class of points reaching that node.\n",
    "\n",
    "Let's look at the root node as an example:\n",
    "\n",
    "![picture labels](images/root%20node.png)\n",
    "\n",
    "  - **serum_creatinine <= 1.815**: The decision rule applied at this node. It splits the data based on whether a patient's `serum_creatinine` is less than or equal to 1.815. If yes, the patient follows the `True` branch; otherwise, it follows the `False` branch.\n",
    "  - **samples = 299**: The total number of samples that reached this node. With no splitting yet, there are 299 patients in the dataset.\n",
    "  - **value = [203, 96]**: The distribution of these samples among the classes at this node. Among the 299 samples, 203 patients belong to the class \"No Death\" and 96 patients belong to the class \"Death\"\n",
    "  - **class = No Death**: The majority class of all the samples that reached this node. If the node is a leaf node, then the majority class represents the predicted class for all the samples that reached the node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3JMVrKKOod3"
   },
   "source": [
    "We can also see that this tree's depth is 3 since we have three decision nodes at depth 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6E76aL5hmkiY"
   },
   "source": [
    "Consider a particular data sample representing a patient. To predict whether the patient died of heart failure, we pass the data sample to the root node. The data sample is routed through the tree by answering the questions at each node, and eventually reaches a leaf node with a final prediction.\n",
    "\n",
    "A patient of `serum_creatinine = 1.700`, `ejection_fraction = 26.0`, `serum_sodium = 120.5` would be predicted as \"Death\" in the tree. When the patient's features vector is passed through the tree, the patient would always follow the `True` branch and end up in the leftmost leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYoRb02IuljH"
   },
   "source": [
    "##### **Q1: You are given a patient with the specified values for each of the dataset features below. Using this and the generated decision tree, classify the patient as either \"Death\" or \"No Death\". Describe the path you took to get to the answer.**\n",
    "  - `anaemia`: 1\n",
    "  - `age`: 50\n",
    "  - `creatinine_phosphokinase`: 1.650\n",
    "  - `diabetes`: 0\n",
    "  - `ejection_fraction`: 29.4\n",
    "  - `high_blood_pressure`: 1\n",
    "  - `platelets`: \t263358.03\n",
    "  - `serum_sodium`: 1.1\n",
    "  - `sex`: 0\n",
    "  - `smoking`: 1\n",
    "  - `serum_creatine`: 1.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9r0I0za7sXV"
   },
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>\n",
    "\n",
    "Answer: No Death; Left, Right, Left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDwVl8LfFIj-"
   },
   "source": [
    "#### **Advantages of Decision Trees**\n",
    "\n",
    "Decision trees are a popular method in machine learning and data analysis. Here are some key benefits:\n",
    "\n",
    "- **Interpretability**: They are easy to understand and interpret, even for non-experts. Understandable models are essential for research and diagnosis in clinical settings. In contrast, other machine learning models, such as neural networks, are much more challenging to interpret.\n",
    "\n",
    "- **Feature Importance**: A good decision tree can naturally indicate which features are most influential in making predictions. For example, the decision tree above uses `serum_creatinine` in multiple nodes, suggesting that this feature is crucial for predicting death in heart failure patients.\n",
    "\n",
    "- **Versatility**: Suitable for both classification and regression tasks.\n",
    "\n",
    "- **Handles Non-linear Relationships**: Can capture non-linear relationships between features and target variables.\n",
    "\n",
    "- **Can Deal with Missing Values**: They can handle missing data points without requiring extra preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQXlPmdWvwXb"
   },
   "source": [
    "### Building Decision Trees for Heart Failure Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPQidjQXtjGO"
   },
   "source": [
    "In the previous section, we showed a decision tree for the heart failure dataset. In this section, we will go through the code used to train and visualize this tree.\n",
    "\n",
    "Let's begin by importing the necessary libraries and the heart failure dataset that was used above.\n",
    "\n",
    "**Step 1: Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eUveB5nKEUWM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                  1.0  265000.00               1.9           130    1   \n",
       "1                  0.0  263358.03               1.1           136    1   \n",
       "2                  0.0  162000.00               1.3           129    1   \n",
       "3                  0.0  210000.00               1.9           137    1   \n",
       "4                  0.0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  DEATH_EVENT  \n",
       "0      0.0            1  \n",
       "1      0.0            1  \n",
       "2      1.0            1  \n",
       "3      0.0            1  \n",
       "4      0.0            1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd       # For processing tabular data\n",
    "from sklearn.tree import DecisionTreeClassifier  # For training a decision tree\n",
    "df = pd.read_csv('heart_failure_data_tut.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nle4L8V_FdVJ"
   },
   "source": [
    "Each row in the table above represents a patient, detailing various characteristics of the patient (i.e. the features), and also whether or not the patient died of heart failure\n",
    "\n",
    "We include the list of features below as a reminder:\n",
    "  - `anaemia`: which is binary 1=true, 0=false\n",
    "  - `age`: ages in year\n",
    "  - `creatinine_phosphokinase`\n",
    "  - `diabetes`: which is binary 1=true, 0=false\n",
    "  - `ejection_fraction`\n",
    "  - `high_blood_pressure`\n",
    "  - `platelets`\n",
    "  - `serum_sodium`\n",
    "  - `sex`\n",
    "  - `smoking`\n",
    "\n",
    "We will be using these features to predict the value in the `DEATH_EVENT` column:\n",
    "-  `DEATH_EVENT`: A report that if the heart failure patient died (1=yes, 0=no).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJMP3a7gqeg4"
   },
   "source": [
    "**Step 2: Process the raw data**\n",
    "\n",
    "Next, we will use the variable `X` to store the input features, which are all the information except the `DEATH_EVENT` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6IS2_U7SFGcZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                  1.0  265000.00               1.9           130    1   \n",
       "1                  0.0  263358.03               1.1           136    1   \n",
       "2                  0.0  162000.00               1.3           129    1   \n",
       "3                  0.0  210000.00               1.9           137    1   \n",
       "4                  0.0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      1.0  \n",
       "3      0.0  \n",
       "4      0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating features and target\n",
    "X_hf = df.drop(columns=['DEATH_EVENT'])\n",
    "\n",
    "# y is the target of the dataset\n",
    "y_hf = df['DEATH_EVENT']\n",
    "\n",
    "X_hf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5sH5vflgxW-"
   },
   "source": [
    "**Step 3: Train a Decision Tree**\n",
    "\n",
    "Next, we will create a decision tree using the `DecisionTreeClassifier` provided by `sklearn`.The documentation about this model contains information about the parameters of the tree and can be found at the following link: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html. We will learn a bit about the important parameters later.\n",
    "\n",
    "\n",
    "Remember, the pipeline for model development in sklearn is **initialize->fit->predict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bRHfH0b-rswC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a decision tree that has a maximum depth of 3\n",
    "dec_tree = DecisionTreeClassifier(random_state=1, max_depth=3)\n",
    "# Train a decision tree\n",
    "dec_tree.fit(X_hf, y_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ry2fdxiJrYjY"
   },
   "source": [
    "**Step 4: Visualize a Decision Tree**\n",
    "\n",
    "We have included a function `visualize_tree`, which plots a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6krwKYq5S8T-"
   },
   "outputs": [],
   "source": [
    "# Import Libraries for Plotting\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "from sklearn import tree\n",
    "\n",
    "def visualize_tree(model, feature_names: list[str], class_names: list[str]):\n",
    "  \"\"\"\n",
    "  Generate an image that visualizes a Sklearn Decision\n",
    "\n",
    "  See here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "\n",
    "  Parameters:\n",
    "      `model` - A Sklearn decision tree model\n",
    "      `feature_names` - List of feature names for the data sample in the dataset\n",
    "      `class_names` - List of class labels/targets in the dataset\n",
    "  \"\"\"\n",
    "  dot_data = tree.export_graphviz(model,\n",
    "                                      feature_names=feature_names,\n",
    "                                      class_names=class_names,\n",
    "                                      filled=True,\n",
    "                                      rounded=True,\n",
    "                                      impurity=False\n",
    "                                  )\n",
    "  return display(graphviz.Source(dot_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Oq1EWiEvewn"
   },
   "source": [
    "To use the function `visualize_tree`, we need to pass 3 input parameters:\n",
    "\n",
    "  - **model**: the decision tree model we want to visualize\n",
    "  - **feature_names**: a list of input features. In this case, it is `[\"age\", \"anaemia\", \"creatinine_phosphokinase\", \"diabetes\", ...]`\n",
    "  - **class_names**: a list of classes. In this case, it is `[\"Death\", \"No Death\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eOg9tXEBvHTb"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20231125.0833)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"933pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 933.00 406.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 402.75)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-402.75 929,-402.75 929,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f1bd97\" stroke=\"black\" d=\"M574.38,-398.75C574.38,-398.75 389.62,-398.75 389.62,-398.75 383.62,-398.75 377.62,-392.75 377.62,-386.75 377.62,-386.75 377.62,-333.75 377.62,-333.75 377.62,-327.75 383.62,-321.75 389.62,-321.75 389.62,-321.75 574.38,-321.75 574.38,-321.75 580.38,-321.75 586.38,-327.75 586.38,-333.75 586.38,-333.75 586.38,-386.75 586.38,-386.75 586.38,-392.75 580.38,-398.75 574.38,-398.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"482\" y=\"-381.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">serum_creatinine &lt;= 1.815</text>\n",
       "<text text-anchor=\"middle\" x=\"482\" y=\"-364.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 299</text>\n",
       "<text text-anchor=\"middle\" x=\"482\" y=\"-346.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [203, 96]</text>\n",
       "<text text-anchor=\"middle\" x=\"482\" y=\"-329.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No Death</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#eda979\" stroke=\"black\" d=\"M460.25,-285.75C460.25,-285.75 289.75,-285.75 289.75,-285.75 283.75,-285.75 277.75,-279.75 277.75,-273.75 277.75,-273.75 277.75,-220.75 277.75,-220.75 277.75,-214.75 283.75,-208.75 289.75,-208.75 289.75,-208.75 460.25,-208.75 460.25,-208.75 466.25,-208.75 472.25,-214.75 472.25,-220.75 472.25,-220.75 472.25,-273.75 472.25,-273.75 472.25,-279.75 466.25,-285.75 460.25,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-268.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ejection_fraction &lt;= 27.5</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 251</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-233.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [190, 61]</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-216.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No Death</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M445.48,-321.36C437.04,-312.61 427.98,-303.21 419.25,-294.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"421.87,-291.83 412.41,-287.06 416.83,-296.69 421.87,-291.83\"/>\n",
       "<text text-anchor=\"middle\" x=\"410.9\" y=\"-306.29\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#83c1ef\" stroke=\"black\" d=\"M677.88,-285.75C677.88,-285.75 502.12,-285.75 502.12,-285.75 496.12,-285.75 490.12,-279.75 490.12,-273.75 490.12,-273.75 490.12,-220.75 490.12,-220.75 490.12,-214.75 496.12,-208.75 502.12,-208.75 502.12,-208.75 677.88,-208.75 677.88,-208.75 683.88,-208.75 689.88,-214.75 689.88,-220.75 689.88,-220.75 689.88,-273.75 689.88,-273.75 689.88,-279.75 683.88,-285.75 677.88,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"590\" y=\"-268.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">serum_creatinine &lt;= 2.05</text>\n",
       "<text text-anchor=\"middle\" x=\"590\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n",
       "<text text-anchor=\"middle\" x=\"590\" y=\"-233.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 35]</text>\n",
       "<text text-anchor=\"middle\" x=\"590\" y=\"-216.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Death</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M518.87,-321.36C527.38,-312.61 536.53,-303.21 545.34,-294.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"547.78,-296.66 552.25,-287.05 542.76,-291.78 547.78,-296.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"553.64\" y=\"-306.29\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#c0e0f7\" stroke=\"black\" d=\"M292.75,-172.75C292.75,-172.75 125.25,-172.75 125.25,-172.75 119.25,-172.75 113.25,-166.75 113.25,-160.75 113.25,-160.75 113.25,-107.75 113.25,-107.75 113.25,-101.75 119.25,-95.75 125.25,-95.75 125.25,-95.75 292.75,-95.75 292.75,-95.75 298.75,-95.75 304.75,-101.75 304.75,-107.75 304.75,-107.75 304.75,-160.75 304.75,-160.75 304.75,-166.75 298.75,-172.75 292.75,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"209\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">serum_sodium &lt;= 143.0</text>\n",
       "<text text-anchor=\"middle\" x=\"209\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n",
       "<text text-anchor=\"middle\" x=\"209\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 25]</text>\n",
       "<text text-anchor=\"middle\" x=\"209\" y=\"-103.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Death</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M318.34,-208.36C304.39,-199.04 289.34,-188.97 274.99,-179.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"277.21,-176.65 266.95,-174 273.32,-182.47 277.21,-176.65\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#ea9b62\" stroke=\"black\" d=\"M449.5,-172.75C449.5,-172.75 334.5,-172.75 334.5,-172.75 328.5,-172.75 322.5,-166.75 322.5,-160.75 322.5,-160.75 322.5,-107.75 322.5,-107.75 322.5,-101.75 328.5,-95.75 334.5,-95.75 334.5,-95.75 449.5,-95.75 449.5,-95.75 455.5,-95.75 461.5,-101.75 461.5,-107.75 461.5,-107.75 461.5,-160.75 461.5,-160.75 461.5,-166.75 455.5,-172.75 449.5,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"392\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">age &lt;= 79.5</text>\n",
       "<text text-anchor=\"middle\" x=\"392\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 209</text>\n",
       "<text text-anchor=\"middle\" x=\"392\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [173, 36]</text>\n",
       "<text text-anchor=\"middle\" x=\"392\" y=\"-103.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No Death</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M380.8,-208.36C381.99,-200.59 383.26,-192.31 384.5,-184.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"387.94,-184.88 385.99,-174.46 381.02,-183.82 387.94,-184.88\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#b0d8f5\" stroke=\"black\" d=\"M118,-59.75C118,-59.75 12,-59.75 12,-59.75 6,-59.75 0,-53.75 0,-47.75 0,-47.75 0,-12 0,-12 0,-6 6,0 12,0 12,0 118,0 118,0 124,0 130,-6 130,-12 130,-12 130,-47.75 130,-47.75 130,-53.75 124,-59.75 118,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40</text>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 25]</text>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Death</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.79,-95.42C142.64,-86.07 128.59,-76.08 115.56,-66.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.7,-64.05 107.53,-61.11 113.65,-69.75 117.7,-64.05\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M272,-59.75C272,-59.75 160,-59.75 160,-59.75 154,-59.75 148,-53.75 148,-47.75 148,-47.75 148,-12 148,-12 148,-6 154,0 160,0 160,0 272,0 272,0 278,0 284,-6 284,-12 284,-12 284,-47.75 284,-47.75 284,-53.75 278,-59.75 272,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"216\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"216\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"216\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No Death</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M211.59,-95.42C212.12,-87.61 212.68,-79.36 213.22,-71.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.7,-71.96 213.89,-61.74 209.72,-71.48 216.7,-71.96\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#e99457\" stroke=\"black\" d=\"M442.5,-59.75C442.5,-59.75 327.5,-59.75 327.5,-59.75 321.5,-59.75 315.5,-53.75 315.5,-47.75 315.5,-47.75 315.5,-12 315.5,-12 315.5,-6 321.5,0 327.5,0 327.5,0 442.5,0 442.5,0 448.5,0 454.5,-6 454.5,-12 454.5,-12 454.5,-47.75 454.5,-47.75 454.5,-53.75 448.5,-59.75 442.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"385\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 195</text>\n",
       "<text text-anchor=\"middle\" x=\"385\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [169, 26]</text>\n",
       "<text text-anchor=\"middle\" x=\"385\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No Death</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M389.41,-95.42C388.88,-87.61 388.32,-79.36 387.78,-71.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"391.28,-71.48 387.11,-61.74 384.3,-71.96 391.28,-71.48\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#88c4ef\" stroke=\"black\" d=\"M581.5,-59.75C581.5,-59.75 484.5,-59.75 484.5,-59.75 478.5,-59.75 472.5,-53.75 472.5,-47.75 472.5,-47.75 472.5,-12 472.5,-12 472.5,-6 478.5,0 484.5,0 484.5,0 581.5,0 581.5,0 587.5,0 593.5,-6 593.5,-12 593.5,-12 593.5,-47.75 593.5,-47.75 593.5,-53.75 587.5,-59.75 581.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"533\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n",
       "<text text-anchor=\"middle\" x=\"533\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 10]</text>\n",
       "<text text-anchor=\"middle\" x=\"533\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Death</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M444.1,-95.42C456.98,-86.07 470.74,-76.08 483.49,-66.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"485.31,-69.83 491.34,-61.12 481.2,-64.16 485.31,-69.83\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M621.5,-164.12C621.5,-164.12 524.5,-164.12 524.5,-164.12 518.5,-164.12 512.5,-158.12 512.5,-152.12 512.5,-152.12 512.5,-116.38 512.5,-116.38 512.5,-110.38 518.5,-104.38 524.5,-104.38 524.5,-104.38 621.5,-104.38 621.5,-104.38 627.5,-104.38 633.5,-110.38 633.5,-116.38 633.5,-116.38 633.5,-152.12 633.5,-152.12 633.5,-158.12 627.5,-164.12 621.5,-164.12\"/>\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-146.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-129.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 14]</text>\n",
       "<text text-anchor=\"middle\" x=\"573\" y=\"-112.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Death</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M584.2,-208.36C582.59,-197.84 580.83,-186.39 579.2,-175.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"582.69,-175.41 577.72,-166.06 575.77,-176.47 582.69,-175.41\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#b4daf5\" stroke=\"black\" d=\"M830.75,-172.75C830.75,-172.75 663.25,-172.75 663.25,-172.75 657.25,-172.75 651.25,-166.75 651.25,-160.75 651.25,-160.75 651.25,-107.75 651.25,-107.75 651.25,-101.75 657.25,-95.75 663.25,-95.75 663.25,-95.75 830.75,-95.75 830.75,-95.75 836.75,-95.75 842.75,-101.75 842.75,-107.75 842.75,-107.75 842.75,-160.75 842.75,-160.75 842.75,-166.75 836.75,-172.75 830.75,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"747\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">serum_sodium &lt;= 134.5</text>\n",
       "<text text-anchor=\"middle\" x=\"747\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n",
       "<text text-anchor=\"middle\" x=\"747\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 21]</text>\n",
       "<text text-anchor=\"middle\" x=\"747\" y=\"-103.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Death</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>8&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M643.59,-208.36C656.66,-199.12 670.75,-189.16 684.2,-179.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"686,-182.66 692.15,-174.03 681.96,-176.95 686,-182.66\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#77bced\" stroke=\"black\" d=\"M758.5,-59.75C758.5,-59.75 661.5,-59.75 661.5,-59.75 655.5,-59.75 649.5,-53.75 649.5,-47.75 649.5,-47.75 649.5,-12 649.5,-12 649.5,-6 655.5,0 661.5,0 661.5,0 758.5,0 758.5,0 764.5,0 770.5,-6 770.5,-12 770.5,-12 770.5,-47.75 770.5,-47.75 770.5,-53.75 764.5,-59.75 758.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"710\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n",
       "<text text-anchor=\"middle\" x=\"710\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 16]</text>\n",
       "<text text-anchor=\"middle\" x=\"710\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Death</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M733.33,-95.42C730.44,-87.43 727.38,-78.98 724.47,-70.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"727.81,-69.87 721.12,-61.65 721.23,-72.25 727.81,-69.87\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#f5d0b5\" stroke=\"black\" d=\"M913,-59.75C913,-59.75 801,-59.75 801,-59.75 795,-59.75 789,-53.75 789,-47.75 789,-47.75 789,-12 789,-12 789,-6 795,0 801,0 801,0 913,0 913,0 919,0 925,-6 925,-12 925,-12 925,-47.75 925,-47.75 925,-53.75 919,-59.75 913,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"857\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n",
       "<text text-anchor=\"middle\" x=\"857\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"857\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = No Death</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M787.65,-95.42C797.3,-86.43 807.59,-76.86 817.21,-67.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"819.41,-70.64 824.35,-61.26 814.65,-65.51 819.41,-70.64\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7fa6b608bf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fill the input to the function\n",
    "visualize_tree(dec_tree, list(X_hf.columns), [\"No Death\", \"Death\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifOnPxbkt04h"
   },
   "source": [
    "### Building Decision Trees for Differentially Expressed Genes (DEGs)\n",
    "\n",
    "Now that we have demonstrated how to train a tree on the Heart Failure dataset, it's your turn to try and train one yourself. You will use the **gene expression dataset of asthma patients** to train a decision tree and predict whether an asthma patient took the medication by looking at their gene expression.\n",
    "\n",
    "The decision tree will identify the DEGs. The goal is to identify genes that can differentiate between the treatment group and the control group, potentially revealing key genes influenced by the medication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRNNPqCC8_Ex"
   },
   "source": [
    "**Step 1: Load the Dataset**\n",
    "\n",
    "The dataset contains gene expression data from the smooth muscle tissue of the airways in asthma patients. This dataset includes two groups: a treatment group that has received the asthma medication dexamethasone, and a control group of asthma patients who have not received any medication. The dataset comprises eight samples, with four samples per group.\n",
    "\n",
    "Below, we read in and pre-process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qjVu4sgH9NqV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 33469) (8,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"airway_rawcounts.csv\")\n",
    "data = data.set_index(\"ensgene\")\n",
    "\n",
    "# Step 1: calculating the sum of counts per gene\n",
    "row_sums = data.sum(axis=1)\n",
    "\n",
    "# Step 2: filter the DataFrame to retain only rows with nonzero total counts\n",
    "data = data[row_sums > 0]\n",
    "# Transpose the DataFrame because it is assumed each row is a data sample\n",
    "data = data.T\n",
    "metadata = pd.DataFrame({\n",
    "    'Condition': ['C', 'T', 'C', 'T', 'C', 'T', 'C', 'T']}, index=data.index)\n",
    "X = data\n",
    "# Create a list of prediction results for the training dataset\n",
    "y = metadata['Condition'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz5Fr0SyUxhp"
   },
   "source": [
    "**Q2: Train a decision tree on the DEG data and visualize it. What is the number of decision nodes in this tree, and what gene does the root node split on? What does the selected gene in the decision node mean?**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Complete the code cell below**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "T8bL4KJ1VG5a"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20231125.0833)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"250pt\" height=\"181pt\"\n",
       " viewBox=\"0.00 0.00 250.00 180.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 176.75)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-176.75 246,-176.75 246,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M218.25,-172.75C218.25,-172.75 23.75,-172.75 23.75,-172.75 17.75,-172.75 11.75,-166.75 11.75,-160.75 11.75,-160.75 11.75,-107.75 11.75,-107.75 11.75,-101.75 17.75,-95.75 23.75,-95.75 23.75,-95.75 218.25,-95.75 218.25,-95.75 224.25,-95.75 230.25,-101.75 230.25,-107.75 230.25,-107.75 230.25,-160.75 230.25,-160.75 230.25,-166.75 224.25,-172.75 218.25,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"121\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ENSG00000187288 &lt;= 11.0</text>\n",
       "<text text-anchor=\"middle\" x=\"121\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n",
       "<text text-anchor=\"middle\" x=\"121\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 4]</text>\n",
       "<text text-anchor=\"middle\" x=\"121\" y=\"-103.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = C</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M100,-59.75C100,-59.75 12,-59.75 12,-59.75 6,-59.75 0,-53.75 0,-47.75 0,-47.75 0,-12 0,-12 0,-6 6,0 12,0 12,0 100,0 100,0 106,0 112,-6 112,-12 112,-12 112,-47.75 112,-47.75 112,-53.75 106,-59.75 100,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = C</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M96.98,-95.42C91.68,-87.07 86.05,-78.21 80.72,-69.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.76,-68.07 75.45,-61.51 77.86,-71.83 83.76,-68.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"69.19\" y=\"-79.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M230,-59.75C230,-59.75 142,-59.75 142,-59.75 136,-59.75 130,-53.75 130,-47.75 130,-47.75 130,-12 130,-12 130,-6 136,0 142,0 142,0 230,0 230,0 236,0 242,-6 242,-12 242,-12 242,-47.75 242,-47.75 242,-53.75 236,-59.75 230,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = T</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.02,-95.42C150.32,-87.07 155.95,-78.21 161.28,-69.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164.14,-71.83 166.55,-61.51 158.24,-68.07 164.14,-71.83\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.81\" y=\"-79.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7fa63ff5c350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## YOUR TURN\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X, y)\n",
    "visualize_tree(dtree, list(X.columns), [\"C\", \"T\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>\n",
    "\n",
    "Answer: There is only 1 decision node. It means that the decision tree determines if a patient is in the control or treatment group by only looking at ENSG000000123610. This specific gene is the key factor that drives the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faLEKlPp57TG"
   },
   "source": [
    "As you can see, the code for training a decision tree is quite simple. However, there are lots of things happening behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5iK6nN80C0V"
   },
   "source": [
    "### Decision Tree Training\n",
    "The core idea behind Decision Tree is to recursively split the dataset into smaller subsets using a decision rule. How does the algorithm decide which feature to select? To understand this, we need to understand the concept of **entropy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VrTzD42JSSQ"
   },
   "source": [
    "#### **Entropy**\n",
    "Entropy is a measure of the amount of uncertainty in the data. Intuitively, for a classification problem, we can understand it as \"if we were to randomly select a point, how confident are we that we know what the point will be.\"\n",
    "\n",
    "Consider the following groups:\n",
    "\n",
    "![name](images/week%206%20entropy%20graph%201.png)\n",
    "\n",
    "\n",
    "If we were to randomly select a data point from Group A, we have a 2/3 chance of the point being green and a 1/3 chance of it being purple, therefore, we can say we are relatively confident that a point chosen from Group A will be green. However, in Group B, there is a 50/50 chance that the point will be green or purple, therefore, we are not confident that we can predict the result of randomly choosing a point. In this case, we can say that Group B has a *higher entropy* than Group A.\n",
    "\n",
    "A group has zero entropy if there is only one class in the group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZBhwb6hjI8T"
   },
   "source": [
    "#### **Splitting with Entropy**\n",
    "\n",
    "A decision tree uses entropy to make decisions. At each internal node, the decision tree examines the points that have reached it and chooses a decision rule that creates two subgroups with low entropy. Given a set of points, the decision tree will generate a few candidate decision rules that split the space. **The tree will choose the split that reduces entropy the most**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClhW-wPHIDvc"
   },
   "source": [
    "**Q3: Below, we plot two different candidate splits. Which split will the decision tree choose: Candidate 1 or Candidate 2? Justify your answer.**\n",
    "\n",
    "![exm](images/candidate_splits.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9r0I0za7sXV"
   },
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>\n",
    "\n",
    "Answer: Split 1 as the left side becomes completely pure (zero entropy), and the right side isolates orange points.\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fm26hJLUJJ8S"
   },
   "source": [
    "#### **Step-by-Step Construction**\n",
    "Decision tree construction is done in a step-by-step manner, starting with the root node. The algorithm can be summarized as follows:\n",
    "\n",
    "1. Observe the group of data points and create a set of candidate decision rules.\n",
    "2. Choose the decision rule that reduces entropy the most and add it to the tree as an internal node. We can then split the group into two groups.\n",
    "3. Looking at the two new groups, pick the group that has the most entropy and repeat steps 1 and 2.\n",
    "4. If we cannot split up the two groups further, add leaves to the tree with the majority class of each node. Then move on to another set of groups and repeat steps 1-4.\n",
    "\n",
    "We then simply repeat the above procedure until various stopping conditions are met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPxhiGwN8Vz5"
   },
   "source": [
    "#### **Splitting Stopping Conditions**\n",
    "\n",
    "There are various conditions in which a node cannot be split, but the main ones are the following:\n",
    "1. **Maximum Tree Depth:** The node we have added has hit the maximum depth we allow.\n",
    "2. **Not Enough Samples**: We cannot split up the space if there are not enough points to create two splits that have a certain number of points. For example, if we split the sample, and one split only has one sample, we may not accept that split.\n",
    "3. **No Reduction in Entropy**: The resultant groups from the split are already pure, and there is no possible reduction in entropy that will result from adding a new split.\n",
    "\n",
    "We can customize these stopping conditions through various hyperparameters.\n",
    "1. `max_depth`: This hyperparameter controls how deep the tree can go.\n",
    "2. `min_samples_leaf`: The minimum number of samples that should reach a leaf.\n",
    "3. `min_impurity_decrease`: The minimum entropy reduction needed to justify a split.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fudUfmAxSydP"
   },
   "source": [
    "#### **Stopping Conditions and Overfitting**\n",
    "One problem we often have in machine learning is the problem of **overfitting**. Overfitting is a situation in machine learning where a model becomes too complex and captures not only the true patterns in the training data but also the noise and outliers. As a result, **the model performs exceptionally well on the training data but struggles to generalize to new, unseen data,** leading to poor performance in real-world applications.\n",
    "\n",
    "Since decision trees are very flexible, they can easily create many splits that perfectly classify the training data. However, these splits may be based on patterns that do not hold in other data sets, leading to a model that is too specialized. When a decision tree overfits, it may have many branches and leaf nodes, capturing subtle and irrelevant distinctions that don't generalize beyond the training set. Each hyperparameter above allows us to limit this problem.\n",
    "\n",
    "To identify overfitting, we often split our data into two different sets:\n",
    "* Training set: This is the data our model sees and trains on.\n",
    "* Testing set: We create this set by removing data from the training set, making sure the model never sees these samples.\n",
    "\n",
    "We split the heart failure dataset into the train and test sets below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "axGt9m-pVa9h"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_hf, y_hf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP5IravFSth2"
   },
   "source": [
    "##### **Max Depth:**\n",
    "\n",
    "The first parameter used to control overfitting is `max_depth`. Since every extra depth of the tree doubles the number of leaves, a sufficiently deep tree eventually assigns each training sample to its own leaf. This over-complexity tends to fit into noise instead of actual trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5wHZ8yVWgCm"
   },
   "source": [
    "**Q4: Test two different values of max_depth, one small tree (<= 3) and one large tree (>=5), and report the train AND test accuracy for both trees. Which depth do you think is overfitting and why?**\n",
    "> Hint: Try using the clf.score(...) built into the decision tree classifier or the accuracy_score function from sklearn metrics.\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Complete the code cell below**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cyop_sohWpEJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8117154811715481\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "## Your Code Here\n",
    "dt1 = DecisionTreeClassifier(max_depth=3)\n",
    "dt1.fit(X_train, y_train)\n",
    "print(dt1.score(X_train, y_train))\n",
    "print(dt1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-YgDHsKAWpGx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916317991631799\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "## Your Code Here\n",
    "dt2 = DecisionTreeClassifier(max_depth=10)\n",
    "dt2.fit(X_train, y_train)\n",
    "print(dt2.score(X_train, y_train))\n",
    "print(dt2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9r0I0za7sXV"
   },
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>\n",
    "\n",
    "Answer: The second one is overfitting because the accuracy for the training set is exceptionally high, while the accuracy is not good enough for the testing set. / There is a wide accuracy gap between the training set and the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19ppe6CkeeOR"
   },
   "source": [
    "##### **Minimum Samples Per Leaf**\n",
    "Another way to avoid overfitting is to specify that there must be more than one point in each leaf. This will force the tree to focus on patterns that appear multiple times, making it more robust to noise. This also prevents deep trees from assigning 1 leaf per point. Below we try two different values for a tree of `max_depth` 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rsZ_eRBmffMq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916317991631799\n",
      "0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "dt1 = DecisionTreeClassifier(min_samples_leaf=1, max_depth = 10)\n",
    "dt1.fit(X_train, y_train)\n",
    "print(dt1.score(X_train, y_train))\n",
    "print(dt1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-TDl8trCfqin"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9037656903765691\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "dt1 = DecisionTreeClassifier(min_samples_leaf=4, max_depth = 10)\n",
    "dt1.fit(X_train, y_train)\n",
    "print(dt1.score(X_train, y_train))\n",
    "print(dt1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3pvRKshhqI2"
   },
   "source": [
    "**Q5: When we increased the minimum samples per leaf, what trends did you observe in the training and testing accuracy?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9r0I0za7sXV"
   },
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>\n",
    "\n",
    "Answer: Increase in testing accuracy, decrease in training accuracy.\r",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9x-lVJhjkDv"
   },
   "source": [
    "##### **Minimum Reduction in Entropy**\n",
    "While the goal of each node is to reduce entropy in each split, sometimes to promote generalization, we don't want to completely purify a given split, as sometimes data can be noisy in real life. To control this, we set the `min_impurity_decrease` parameter. If the split isn't \"strong enough,\" the tree won't make the split. Below, we increase the `min_impurity_decrease` value from 0.0 to 0.01 for a very deep tree. Notice how the training accuracy significantly decreased, but the testing accuracy significantly increased.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aIw7rpDUk9Rp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916317991631799\n",
      "0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "dt1 = DecisionTreeClassifier(min_impurity_decrease = 0.00, max_depth=10)\n",
    "dt1.fit(X_train, y_train)\n",
    "print(dt1.score(X_train, y_train))\n",
    "print(dt1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Bgi9d6d_kfev"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8117154811715481\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "dt2 = DecisionTreeClassifier(min_impurity_decrease =0.01, max_depth = 10)\n",
    "dt2.fit(X_train, y_train)\n",
    "print(dt2.score(X_train, y_train))\n",
    "print(dt2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JCPA0qLzarH"
   },
   "source": [
    "## **Graded Exercise: (5 marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFjGAU7mjHTD"
   },
   "source": [
    "**GQ1 (2 marks): In the cell below, we load in the breast cancer dataset for you. Fit decision trees with depths between 1-6 (1,2,...,6) and plot the training and testing accuracies for each tree. Do any of the trees overfit, and if so, at what depth?**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ITBYp5srjHWL"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "feature_names = data.feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5wUInhBclEEG"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = range(1, 7)\n",
    "# Loop through different depths and collect the train and test accuracy\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# YOUR CODE HERE: fit decision trees with depth in depths\n",
    "for max_depth in depths:\n",
    "  dec_tree = DecisionTreeClassifier(random_state = 42, max_depth=max_depth)\n",
    "  dec_tree.fit(X_train, y_train)\n",
    "  train_accs.append(accuracy_score(y_train, dec_tree.predict(X_train)))\n",
    "  test_accs.append(accuracy_score(y_test, dec_tree.predict(X_test)))\n",
    "\n",
    "# YOUR CODE HERE: plot the training and testing accuracies across depths\n",
    "plt.plot(depths, train_accs, label=\"Training Accuracy\")\n",
    "plt.plot(depths, test_accs, label=\"Testing Accuracy\")\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHg_2-MGq4vW"
   },
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>\n",
    "\n",
    "Answer: The Best Depth is 3-5 (because it reaches the highest testing accuracy). The tree starts overfitting at depth 6 because the test accuracy starts to drop.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1MzeFNloGNg"
   },
   "source": [
    "**GQ2 (2 marks): From the above question, pick the decision tree with the highest testing accuracy and visualize it. What feature does the tree split on at the root node? Additionally, how many leaf nodes are there?**\n",
    "\n",
    "<span style=\"background-color: #FFD700\">**Write your code below**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "N38zNNIqoFdN"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20231125.0833)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1188pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 1187.75 406.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 402.75)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-402.75 1183.75,-402.75 1183.75,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#aed7f4\" stroke=\"black\" d=\"M658.62,-398.75C658.62,-398.75 445.38,-398.75 445.38,-398.75 439.38,-398.75 433.38,-392.75 433.38,-386.75 433.38,-386.75 433.38,-333.75 433.38,-333.75 433.38,-327.75 439.38,-321.75 445.38,-321.75 445.38,-321.75 658.62,-321.75 658.62,-321.75 664.62,-321.75 670.62,-327.75 670.62,-333.75 670.62,-333.75 670.62,-386.75 670.62,-386.75 670.62,-392.75 664.62,-398.75 658.62,-398.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-381.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mean concave points &lt;= 0.051</text>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-364.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 455</text>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-346.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [169, 286]</text>\n",
       "<text text-anchor=\"middle\" x=\"552\" y=\"-329.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#45a3e7\" stroke=\"black\" d=\"M496.88,-285.75C496.88,-285.75 345.12,-285.75 345.12,-285.75 339.12,-285.75 333.12,-279.75 333.12,-273.75 333.12,-273.75 333.12,-220.75 333.12,-220.75 333.12,-214.75 339.12,-208.75 345.12,-208.75 345.12,-208.75 496.88,-208.75 496.88,-208.75 502.88,-208.75 508.88,-214.75 508.88,-220.75 508.88,-220.75 508.88,-273.75 508.88,-273.75 508.88,-279.75 502.88,-285.75 496.88,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-268.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst radius &lt;= 16.83</text>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 282</text>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-233.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [16, 266]</text>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-216.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M507.28,-321.36C496.64,-312.34 485.18,-302.63 474.2,-293.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"476.56,-290.74 466.67,-286.95 472.04,-296.08 476.56,-290.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"467.57\" y=\"-306.21\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#e89153\" stroke=\"black\" d=\"M800.25,-285.75C800.25,-285.75 587.75,-285.75 587.75,-285.75 581.75,-285.75 575.75,-279.75 575.75,-273.75 575.75,-273.75 575.75,-220.75 575.75,-220.75 575.75,-214.75 581.75,-208.75 587.75,-208.75 587.75,-208.75 800.25,-208.75 800.25,-208.75 806.25,-208.75 812.25,-214.75 812.25,-220.75 812.25,-220.75 812.25,-273.75 812.25,-273.75 812.25,-279.75 806.25,-285.75 800.25,-285.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-268.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst concave points &lt;= 0.147</text>\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 173</text>\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-233.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [153, 20]</text>\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-216.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M600.47,-321.36C612.12,-312.25 624.68,-302.44 636.69,-293.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"638.83,-295.82 644.55,-286.9 634.52,-290.3 638.83,-295.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"642.71\" y=\"-306.11\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#3d9fe6\" stroke=\"black\" d=\"M281,-172.75C281,-172.75 157,-172.75 157,-172.75 151,-172.75 145,-166.75 145,-160.75 145,-160.75 145,-107.75 145,-107.75 145,-101.75 151,-95.75 157,-95.75 157,-95.75 281,-95.75 281,-95.75 287,-95.75 293,-101.75 293,-107.75 293,-107.75 293,-160.75 293,-160.75 293,-166.75 287,-172.75 281,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">area error &lt;= 48.7</text>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 263</text>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 258]</text>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-103.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M352.05,-208.36C334.59,-198.77 315.71,-188.39 297.81,-178.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"299.76,-175.63 289.31,-173.89 296.39,-181.77 299.76,-175.63\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#f8ddc9\" stroke=\"black\" d=\"M500.25,-172.75C500.25,-172.75 341.75,-172.75 341.75,-172.75 335.75,-172.75 329.75,-166.75 329.75,-160.75 329.75,-160.75 329.75,-107.75 329.75,-107.75 329.75,-101.75 335.75,-95.75 341.75,-95.75 341.75,-95.75 500.25,-95.75 500.25,-95.75 506.25,-95.75 512.25,-101.75 512.25,-107.75 512.25,-107.75 512.25,-160.75 512.25,-160.75 512.25,-166.75 506.25,-172.75 500.25,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mean texture &lt;= 16.19</text>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 8]</text>\n",
       "<text text-anchor=\"middle\" x=\"421\" y=\"-103.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M421,-208.36C421,-200.59 421,-192.31 421,-184.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"424.5,-184.48 421,-174.48 417.5,-184.48 424.5,-184.48\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#3b9ee5\" stroke=\"black\" d=\"M118,-59.75C118,-59.75 12,-59.75 12,-59.75 6,-59.75 0,-53.75 0,-47.75 0,-47.75 0,-12 0,-12 0,-6 6,0 12,0 12,0 118,0 118,0 124,0 130,-6 130,-12 130,-12 130,-47.75 130,-47.75 130,-53.75 124,-59.75 118,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 260</text>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 257]</text>\n",
       "<text text-anchor=\"middle\" x=\"65\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.09,-95.42C147.89,-85.98 132.71,-75.89 118.67,-66.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"120.69,-63.69 110.42,-61.07 116.81,-69.52 120.69,-63.69\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#f2c09c\" stroke=\"black\" d=\"M277.62,-59.75C277.62,-59.75 160.38,-59.75 160.38,-59.75 154.38,-59.75 148.38,-53.75 148.38,-47.75 148.38,-47.75 148.38,-12 148.38,-12 148.38,-6 154.38,0 160.38,0 160.38,0 277.62,0 277.62,0 283.62,0 289.62,-6 289.62,-12 289.62,-12 289.62,-47.75 289.62,-47.75 289.62,-53.75 283.62,-59.75 277.62,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"219\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M219,-95.42C219,-87.7 219,-79.55 219,-71.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.5,-71.74 219,-61.74 215.5,-71.74 222.5,-71.74\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M414.75,-59.75C414.75,-59.75 319.25,-59.75 319.25,-59.75 313.25,-59.75 307.25,-53.75 307.25,-47.75 307.25,-47.75 307.25,-12 307.25,-12 307.25,-6 313.25,0 319.25,0 319.25,0 414.75,0 414.75,0 420.75,0 426.75,-6 426.75,-12 426.75,-12 426.75,-47.75 426.75,-47.75 426.75,-53.75 420.75,-59.75 414.75,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"367\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"middle\" x=\"367\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n",
       "<text text-anchor=\"middle\" x=\"367\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M401.05,-95.42C396.74,-87.25 392.17,-78.59 387.83,-70.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"390.95,-68.78 383.19,-61.57 384.76,-72.05 390.95,-68.78\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#ea985d\" stroke=\"black\" d=\"M573.62,-59.75C573.62,-59.75 456.38,-59.75 456.38,-59.75 450.38,-59.75 444.38,-53.75 444.38,-47.75 444.38,-47.75 444.38,-12 444.38,-12 444.38,-6 450.38,0 456.38,0 456.38,0 573.62,0 573.62,0 579.62,0 585.62,-6 585.62,-12 585.62,-12 585.62,-47.75 585.62,-47.75 585.62,-53.75 579.62,-59.75 573.62,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"515\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n",
       "<text text-anchor=\"middle\" x=\"515\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"515\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M455.74,-95.42C463.82,-86.61 472.43,-77.24 480.5,-68.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"482.84,-71.08 487.02,-61.35 477.68,-66.34 482.84,-71.08\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#f4fafe\" stroke=\"black\" d=\"M786.75,-172.75C786.75,-172.75 601.25,-172.75 601.25,-172.75 595.25,-172.75 589.25,-166.75 589.25,-160.75 589.25,-160.75 589.25,-107.75 589.25,-107.75 589.25,-101.75 595.25,-95.75 601.25,-95.75 601.25,-95.75 786.75,-95.75 786.75,-95.75 792.75,-95.75 798.75,-101.75 798.75,-107.75 798.75,-107.75 798.75,-160.75 798.75,-160.75 798.75,-166.75 792.75,-172.75 786.75,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst perimeter &lt;= 115.25</text>\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 18]</text>\n",
       "<text text-anchor=\"middle\" x=\"694\" y=\"-103.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M694,-208.36C694,-200.59 694,-192.31 694,-184.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"697.5,-184.48 694,-174.48 690.5,-184.48 697.5,-184.48\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#e5833c\" stroke=\"black\" d=\"M1083.88,-172.75C1083.88,-172.75 860.12,-172.75 860.12,-172.75 854.12,-172.75 848.12,-166.75 848.12,-160.75 848.12,-160.75 848.12,-107.75 848.12,-107.75 848.12,-101.75 854.12,-95.75 860.12,-95.75 860.12,-95.75 1083.88,-95.75 1083.88,-95.75 1089.88,-95.75 1095.88,-101.75 1095.88,-107.75 1095.88,-107.75 1095.88,-160.75 1095.88,-160.75 1095.88,-166.75 1089.88,-172.75 1083.88,-172.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"972\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">fractal dimension error &lt;= 0.013</text>\n",
       "<text text-anchor=\"middle\" x=\"972\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 138</text>\n",
       "<text text-anchor=\"middle\" x=\"972\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [136, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"972\" y=\"-103.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M788.89,-208.36C813.92,-198.37 841.07,-187.53 866.61,-177.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"867.67,-180.68 875.66,-173.72 865.07,-174.18 867.67,-180.68\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#65b3eb\" stroke=\"black\" d=\"M712.5,-59.75C712.5,-59.75 615.5,-59.75 615.5,-59.75 609.5,-59.75 603.5,-53.75 603.5,-47.75 603.5,-47.75 603.5,-12 603.5,-12 603.5,-6 609.5,0 615.5,0 615.5,0 712.5,0 712.5,0 718.5,0 724.5,-6 724.5,-12 724.5,-12 724.5,-47.75 724.5,-47.75 724.5,-53.75 718.5,-59.75 712.5,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"664\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n",
       "<text text-anchor=\"middle\" x=\"664\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 18]</text>\n",
       "<text text-anchor=\"middle\" x=\"664\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M682.91,-95.42C680.6,-87.52 678.15,-79.17 675.81,-71.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"679.2,-70.3 673.03,-61.68 672.48,-72.26 679.2,-70.3\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M871.62,-59.75C871.62,-59.75 754.38,-59.75 754.38,-59.75 748.38,-59.75 742.38,-53.75 742.38,-47.75 742.38,-47.75 742.38,-12 742.38,-12 742.38,-6 748.38,0 754.38,0 754.38,0 871.62,0 871.62,0 877.62,0 883.62,-6 883.62,-12 883.62,-12 883.62,-47.75 883.62,-47.75 883.62,-53.75 877.62,-59.75 871.62,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"813\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n",
       "<text text-anchor=\"middle\" x=\"813\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"813\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M737.97,-95.42C748.53,-86.34 759.78,-76.66 770.27,-67.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"772.43,-70.39 777.73,-61.22 767.87,-65.09 772.43,-70.39\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M1030.62,-59.75C1030.62,-59.75 913.38,-59.75 913.38,-59.75 907.38,-59.75 901.38,-53.75 901.38,-47.75 901.38,-47.75 901.38,-12 901.38,-12 901.38,-6 907.38,0 913.38,0 913.38,0 1030.62,0 1030.62,0 1036.62,0 1042.62,-6 1042.62,-12 1042.62,-12 1042.62,-47.75 1042.62,-47.75 1042.62,-53.75 1036.62,-59.75 1030.62,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"972\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 136</text>\n",
       "<text text-anchor=\"middle\" x=\"972\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [136, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"972\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M972,-95.42C972,-87.7 972,-79.55 972,-71.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"975.5,-71.74 972,-61.74 968.5,-71.74 975.5,-71.74\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M1167.75,-59.75C1167.75,-59.75 1072.25,-59.75 1072.25,-59.75 1066.25,-59.75 1060.25,-53.75 1060.25,-47.75 1060.25,-47.75 1060.25,-12 1060.25,-12 1060.25,-6 1066.25,0 1072.25,0 1072.25,0 1167.75,0 1167.75,0 1173.75,0 1179.75,-6 1179.75,-12 1179.75,-12 1179.75,-47.75 1179.75,-47.75 1179.75,-53.75 1173.75,-59.75 1167.75,-59.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"1120\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"1120\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"1120\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1026.69,-95.42C1040.34,-85.98 1054.93,-75.89 1068.42,-66.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1070.08,-69.66 1076.32,-61.09 1066.1,-63.9 1070.08,-69.66\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7fa63ee5cc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dec_tree = DecisionTreeClassifier(random_state = 42, max_depth=3)\n",
    "dec_tree.fit(X_train, y_train)\n",
    "visualize_tree(dec_tree, feature_names, data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILSrkVuIq2fU"
   },
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>\n",
    "\n",
    "Answer: Mean Concave Points, 8 leaves.\r",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0uY-DThpOKq"
   },
   "source": [
    "**GQ3 (1 mark): Nick has a dataset with 500 *unique* training points, and he fits a tree with the following parameters and achieves 100% training accuracy. Should Nick be happy with these results? If not, what does Nick need to do to confirm that his tree is good?**\n",
    "\n",
    "* Min Depth: 8\n",
    "* Min Samples per Leaf: 1\n",
    "* Min Entropy Decrease: 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvy7Da13qz8s"
   },
   "source": [
    "<span style=\"background-color: #FFD700\">**Write your answer below**</span>\n",
    "\n",
    "Answer: No, Nick should be cautious, as those hyperparameters allow for one leaf per data point, and the resulting tree might be overfitting.\r",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsLLdnKk5MwK"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, decision trees are powerful and intuitive tools in machine learning that offer both flexibility and interpretability. By iteratively splitting data based on feature values, decision trees can model complex relationships and make predictions for both classification and regression tasks. Additionally, the ability of a tree to be visualized and easily interpreted makes it a powerful analytic tool in your toolbox.\n",
    "\n",
    "However, with this flexibility comes the risk of overfitting, where the model becomes too tailored to the training data and loses its ability to generalize to new data. To prevent this, various parameters can be modified to help adjust the tendency of a tree to fit into noise. Understanding the balance between complexity and generalization is key to effectively using decision trees. With this knowledge, you can confidently apply decision trees to a wide range of problems, making them a valuable tool in your machine learning toolkit."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
